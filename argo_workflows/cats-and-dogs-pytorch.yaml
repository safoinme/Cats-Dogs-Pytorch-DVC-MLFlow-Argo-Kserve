apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: cats-and-dogs-pytorch-workflow
spec:
  entrypoint: cats-and-dogs-pytorch
  volumes:
  - name: git-private-key
    secret:
      secretName: git-secret-ssh
  templates:
  - name: cats-and-dogs-pytorch
    steps:
    #- - name: data-augmentation          # train-original is run after pre-process and at same time with train-preprocessed step
    #    template: dataset-augment
    - - name: train-original           # train-original is run after pre-process and at same time with train-preprocessed step
        template: cats-and-dogs-train
    - - name: retrieve-best-model           # retrieve-best-model is run before the following steps and after training steps
        template: retrive-best-model
    - - name: deploy-model           # deploy-model is run after the retrieve-best-model step and only if retrieve-best-model have tf result
        template: cats-dogs-deploy-torch-serving
        when: "{{steps.retrieve-best-model.outputs.parameters.model-flavor}} == pytorch"
        arguments:
          parameters:
            - name: model-name-version
              value: "{{steps.retrieve-best-model.outputs.parameters.model-name-version}}"
            - name: predictor
              value: "pytorch"
            - name: model-uri
              value: "{{steps.retrieve-best-model.outputs.parameters.model-uri}}"

  - name: cats-and-dogs-train
    inputs:
      artifacts:
      - name: repo-source
        path: /app
        git:
          repo: https://github.com/safoinme/Cats-Dogs-Pytorch-DVC-MLFlow-Argo-Kserve.git
          revision: "main"
    container:
      image: safoinme/pytorch-cpu-mlflow-dvc:0.1.0
      env:
          - name: MLFLOW_TRACKING_URI
            valueFrom:
              secretKeyRef:
                name: mlflow-access
                key: MLFLOW_TRACKING_URI
          - name: MLFLOW_S3_ENDPOINT_URL
            valueFrom:
              secretKeyRef:
                name: mlflow-access
                key: MLFLOW_S3_ENDPOINT_URL
          - name: AWS_ACCESS_KEY_ID
            valueFrom:
              secretKeyRef:
                name: mlflow-access
                key: AWS_ACCESS_KEY_ID
          - name: AWS_SECRET_ACCESS_KEY
            valueFrom:
              secretKeyRef:
                name: mlflow-access
                key: AWS_SECRET_ACCESS_KEY
          - name: DVC_BUCKET
            valueFrom:
              secretKeyRef:
                name: dvc-access
                key: DVC_BUCKET
          - name: DVC_S3_ENDPOINT_URL
            valueFrom:
              secretKeyRef:
                name: dvc-access
                key: DVC_S3_ENDPOINT_URL
      command: [sh, -c]
      args: 
        - ./config_git.sh;
          python3 train.py
      workingDir: /app
  - name: retrive-best-model
    inputs:
      artifacts:
      - name: repo-source
        path: /app
        git:
          repo: https://github.com/safoinme/Cats-Dogs-Pytorch-DVC-MLFlow-Argo-Kserve.git
          revision: "main"
    container:
      image: safoinme/pytorch-cpu-mlflow-dvc:0.1.1
      env:
          - name: MLFLOW_TRACKING_URI
            valueFrom:
              secretKeyRef:
                name: mlflow-access
                key: MLFLOW_TRACKING_URI
          - name: MLFLOW_S3_ENDPOINT_URL
            valueFrom:
              secretKeyRef:
                name: mlflow-access
                key: MLFLOW_S3_ENDPOINT_URL
          - name: AWS_ACCESS_KEY_ID
            valueFrom:
              secretKeyRef:
                name: mlflow-access
                key: AWS_ACCESS_KEY_ID
          - name: AWS_SECRET_ACCESS_KEY
            valueFrom:
              secretKeyRef:
                name: mlflow-access
                key: AWS_SECRET_ACCESS_KEY
      command: [sh, -c]
      args: 
        - python3 experiment_comparaison.py;     
          ls /tmp/models/; 
      workingDir: /app
    outputs:
      parameters:
        - name: model-flavor
          valueFrom:
            path: /tmp/artifact_downloads/model/data/save_format.txt
        - name: model-name-version
          valueFrom:
            path: /tmp/model_name_version.txt
        - name: model-uri
          valueFrom:
            path: /tmp/best_model_artifact_uri.txt
  
  - name: cats-dogs-deploy-torch-serving
    inputs:
      parameters:
      - name: model-uri
      - name: model-name-version
      - name: predictor
    resource:
      action: create
      manifest: |
        apiVersion: "serving.kserve.io/v1beta1"
        kind: "InferenceService"
        metadata:
          name: "{{inputs.parameters.model-name-version}}"
          namespace: kserve-deployement
        spec:
          predictor:
            serviceAccountName: stminio
            {{inputs.parameters.predictor}}:
              storageUri: "{{inputs.parameters.model-uri}}"
              resources:
                limits:
                  memory: 2Gi
                  cpu: "1"
  #- name: mnist-deploy-tf-serving
  #  inputs:
  #    parameters:
  #    - name: model-uri
  #  container:
  #    image: safoinme/python-mlflow-expirements:0.1.0
  #    command: [sh, -c]
  #    args: ["echo {{inputs.parameters.model-uri}} "]  

  #- name: mnist-deploy-tf-serving
  #  resource:
  #    action: create
      # successCondition and failureCondition are optional expressions which are
      # evaluated upon every update of the resource. If failureCondition is ever
      # evaluated to true, the step is considered failed. Likewise, if successCondition
      # is ever evaluated to true the step is considered successful. It uses kubernetes
      # label selection syntax and can be applied against any field of the resource
      # (not just labels). Multiple AND conditions can be represented by comma
      # delimited expressions. For more details, see:
      # https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
  #    successCondition: status.succeeded > 0
  #    failureCondition: status.failed > 3
  #    manifest: |
  #      apiVersion: apps/v1
  #      kind: Deployment
  #      metadata:
  #        name: tf-serving-deployment
  #      spec:
  #        replicas: 1
  #        template:
  #          metadata:
  #            labels:
  #              app: tf-serving-server
  #          spec:
  #            containers:
  #            - name: tf-serving-container
  #              image: tensorflow/serving:latest
  #              ports:
  #              - containerPort: 8500
  #      ---
  #      apiVersion: v1
  #      kind: Service
  #      metadata:
  #        labels:
  #          run: tf-serving-service
  #        name: tf-serving-service
  #      spec:
  #        ports:
  #        - port: 8500
  #          targetPort: 8500